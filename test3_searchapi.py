#!/usr/bin/env python3

import requests
import hashlib
import json
from datetime import datetime
from bs4 import BeautifulSoup
from html2text import html2text
import time

class FlomoSearchAPI:
    def __init__(self, token):
        self.token = token
        self.salt = "dbbc3dd73364b4084c3a69346e0ce2b2"
        self.base_url = "https://flomoapp.com/api/v1/memo/updated/"
        
    def _generate_params(self, extra_params=None):
        """ç”ŸæˆAPIå‚æ•°å’Œç­¾å"""
        params = {
            "timestamp": str(int(datetime.now().timestamp())),
            "api_key": "flomo_web",
            "app_version": "4.0",
            "platform": "web",
            "webp": "1"
        }
        
        if extra_params:
            params.update(extra_params)
        
        # ç”Ÿæˆç­¾å
        param_str = "&".join([f"{k}={v}" for k, v in sorted(params.items())])
        sign = hashlib.md5((param_str + self.salt).encode("utf-8")).hexdigest()
        params["sign"] = sign
        
        return params
    
    def search(self, query, limit=50):
        """
        æœç´¢å¤‡å¿˜å½•
        
        Args:
            query: æœç´¢å…³é”®è¯
            limit: ç»“æœæ•°é‡é™åˆ¶ï¼ˆå®é™…è¿”å›æ•°é‡å¯èƒ½å°‘äºæ­¤å€¼ï¼‰
        
        Returns:
            æœç´¢ç»“æœåˆ—è¡¨
        """
        if not query.strip():
            return []
        
        try:
            params = self._generate_params({
                "q": query,
                "limit": str(limit)
            })
            
            headers = {"Authorization": self.token}
            
            print(f"ğŸ” æœç´¢å…³é”®è¯: '{query}'")
            print(f"ğŸ“Š è¯·æ±‚å‚æ•°: {params}")
            
            response = requests.get(self.base_url, params=params, headers=headers)
            
            if response.status_code == 200:
                data = response.json()
                if data.get("code") == 0:
                    results = data.get("data", [])
                    print(f"âœ… æœç´¢æˆåŠŸï¼Œæ‰¾åˆ° {len(results)} æ¡ç»“æœ")
                    return results
                else:
                    print(f"âŒ APIé”™è¯¯: {data.get('message')}")
                    return []
            else:
                print(f"âŒ HTTPé”™è¯¯: {response.status_code}")
                return []
                
        except Exception as e:
            print(f"ğŸ’¥ æœç´¢å¼‚å¸¸: {e}")
            return []
    
    def search_with_pagination(self, query, max_results=200):
        """
        æ”¯æŒåˆ†é¡µçš„æœç´¢ï¼ˆè·å–æ›´å¤šç»“æœï¼‰
        
        Args:
            query: æœç´¢å…³é”®è¯
            max_results: æœ€å¤§ç»“æœæ•°é‡
        """
        all_results = []
        latest_slug = None
        latest_updated_at = None
        page = 1
        
        while len(all_results) < max_results:
            try:
                search_params = {"q": query, "limit": "50"}
                
                # æ·»åŠ åˆ†é¡µå‚æ•°
                if latest_slug and latest_updated_at:
                    search_params.update({
                        "latest_slug": latest_slug,
                        "latest_updated_at": str(latest_updated_at)
                    })
                
                params = self._generate_params(search_params)
                headers = {"Authorization": self.token}
                
                print(f"ğŸ” æœç´¢ç¬¬ {page} é¡µ: '{query}'")
                
                response = requests.get(self.base_url, params=params, headers=headers)
                
                if response.status_code == 200:
                    data = response.json()
                    if data.get("code") == 0:
                        results = data.get("data", [])
                        
                        if not results:
                            break
                        
                        all_results.extend(results)
                        print(f"ğŸ“„ ç¬¬ {page} é¡µè·å– {len(results)} æ¡ç»“æœ")
                        
                        # å¦‚æœè¿™é¡µç»“æœå°‘äº50æ¡ï¼Œè¯´æ˜æ²¡æœ‰æ›´å¤šæ•°æ®äº†
                        if len(results) < 50:
                            break
                        
                        # è®¾ç½®ä¸‹ä¸€é¡µå‚æ•°
                        last_memo = results[-1]
                        latest_slug = last_memo["slug"]
                        latest_updated_at = int(datetime.fromisoformat(last_memo["updated_at"]).timestamp())
                        
                        page += 1
                        time.sleep(0.5)  # é¿å…è¯·æ±‚è¿‡å¿«
                    else:
                        print(f"âŒ APIé”™è¯¯: {data.get('message')}")
                        break
                else:
                    print(f"âŒ HTTPé”™è¯¯: {response.status_code}")
                    break
                    
            except Exception as e:
                print(f"ğŸ’¥ æœç´¢å¼‚å¸¸: {e}")
                break
        
        print(f"âœ… æœç´¢å®Œæˆï¼Œæ€»å…±æ‰¾åˆ° {len(all_results)} æ¡ç»“æœ")
        return all_results[:max_results]
    
    def parse_search_result(self, memo):
        """è§£ææœç´¢ç»“æœ"""
        content = memo.get('content', '')
        
        # è½¬æ¢HTMLä¸ºæ–‡æœ¬
        soup = BeautifulSoup(content, 'html.parser')
        plain_text = soup.get_text(separator='\n', strip=True)
        markdown_text = html2text(content).strip()
        
        # æå–æ ‡ç­¾
        import re
        tags = re.findall(r'#([^\s#]+)', content)
        
        # æ–‡ä»¶ä¿¡æ¯
        files = memo.get('files', [])
        file_info = []
        for file_item in files:
            file_info.append({
                'id': file_item.get('id'),
                'type': file_item.get('type'),
                'name': file_item.get('name'),
                'size': file_item.get('size')
            })
        
        return {
            'slug': memo.get('slug'),
            'created_at': memo.get('created_at'),
            'updated_at': memo.get('updated_at'),
            'creator_id': memo.get('creator_id'),
            'source': memo.get('source'),
            'pin': memo.get('pin'),
            'linked_count': memo.get('linked_count'),
            'original_html': content,
            'plain_text': plain_text,
            'markdown': markdown_text,
            'tags': tags,
            'files': file_info,
            'has_files': len(files) > 0,
            'word_count': len(plain_text),
            'url': f"https://v.flomoapp.com/mine/?memo_id={memo.get('slug')}"
        }
    
    def advanced_search(self, query, include_tags=None, exclude_tags=None, 
                       has_files=None, date_from=None, date_to=None):
        """
        é«˜çº§æœç´¢ï¼ˆåœ¨æœç´¢ç»“æœåŸºç¡€ä¸Šè¿›è¡Œè¿‡æ»¤ï¼‰
        
        Args:
            query: åŸºç¡€æœç´¢å…³é”®è¯
            include_tags: å¿…é¡»åŒ…å«çš„æ ‡ç­¾åˆ—è¡¨
            exclude_tags: å¿…é¡»æ’é™¤çš„æ ‡ç­¾åˆ—è¡¨  
            has_files: True=åªè¦æœ‰æ–‡ä»¶çš„, False=åªè¦æ²¡æ–‡ä»¶çš„, None=ä¸é™åˆ¶
            date_from: å¼€å§‹æ—¥æœŸ (datetimeå¯¹è±¡)
            date_to: ç»“æŸæ—¥æœŸ (datetimeå¯¹è±¡)
        """
        # å…ˆè¿›è¡ŒåŸºç¡€æœç´¢
        base_results = self.search_with_pagination(query, max_results=500)
        
        if not base_results:
            return []
        
        # è§£ææ‰€æœ‰ç»“æœ
        parsed_results = [self.parse_search_result(memo) for memo in base_results]
        
        # åº”ç”¨è¿‡æ»¤æ¡ä»¶
        filtered_results = []
        
        for result in parsed_results:
            # æ ‡ç­¾è¿‡æ»¤
            if include_tags:
                if not all(tag in result['tags'] for tag in include_tags):
                    continue
            
            if exclude_tags:
                if any(tag in result['tags'] for tag in exclude_tags):
                    continue
            
            # æ–‡ä»¶è¿‡æ»¤
            if has_files is not None:
                if has_files and not result['has_files']:
                    continue
                elif not has_files and result['has_files']:
                    continue
            
            # æ—¥æœŸè¿‡æ»¤
            if date_from or date_to:
                try:
                    memo_date = datetime.fromisoformat(result['created_at'].replace('Z', '+00:00'))
                    if date_from and memo_date < date_from:
                        continue
                    if date_to and memo_date > date_to:
                        continue
                except:
                    continue
            
            filtered_results.append(result)
        
        print(f"ğŸ¯ é«˜çº§æœç´¢å®Œæˆï¼Œä» {len(parsed_results)} æ¡ç»“æœä¸­ç­›é€‰å‡º {len(filtered_results)} æ¡")
        return filtered_results
    
    def get_file_details(self, file_ids):
        """
        è·å–æ–‡ä»¶è¯¦ç»†ä¿¡æ¯
        
        Args:
            file_ids: æ–‡ä»¶IDåˆ—è¡¨
        """
        if not file_ids:
            return []
        
        try:
            # æ„å»ºæ–‡ä»¶APIå‚æ•°
            file_params = {}
            for i, file_id in enumerate(file_ids):
                file_params[f"ids[{i}]"] = str(file_id)
            
            params = self._generate_params(file_params)
            headers = {"Authorization": self.token}
            
            response = requests.get(
                "https://flomoapp.com/api/v1/file/",
                params=params,
                headers=headers
            )
            
            if response.status_code == 200:
                data = response.json()
                if data.get("code") == 0:
                    return data.get("data", [])
            
            return []
            
        except Exception as e:
            print(f"ğŸ’¥ è·å–æ–‡ä»¶ä¿¡æ¯å¤±è´¥: {e}")
            return []

def demo_search_functionality():
    """æ¼”ç¤ºæœç´¢åŠŸèƒ½"""
    # é…ç½®token
    TOKEN = "Bearer 6782846|pguJkOHgJ21KYW4oHfrEF0syJvHRygKI5a53Mitf"
    
    search_api = FlomoSearchAPI(TOKEN)
    
    print("ğŸš€ Flomo æœç´¢åŠŸèƒ½æ¼”ç¤º")
    print("="*60)
    
    # 1. åŸºç¡€æœç´¢
    print("\n1ï¸âƒ£ åŸºç¡€æœç´¢æ¼”ç¤º")
    results = search_api.search("å¤•é˜³", limit=10)
    
    if results:
        print(f"ğŸ“‹ æœç´¢ç»“æœé¢„è§ˆ:")
        for i, memo in enumerate(results[:3], 1):
            parsed = search_api.parse_search_result(memo)
            print(f"\n   {i}. [{parsed['created_at']}]")
            print(f"      å†…å®¹: {parsed['plain_text'][:80]}...")
            print(f"      æ ‡ç­¾: {parsed['tags']}")
            print(f"      æ–‡ä»¶: {len(parsed['files'])} ä¸ª")
            print(f"      é“¾æ¥: {parsed['url']}")
    
    # 2. åˆ†é¡µæœç´¢
    print(f"\n2ï¸âƒ£ åˆ†é¡µæœç´¢æ¼”ç¤ºï¼ˆè·å–æ›´å¤šç»“æœï¼‰")
    all_results = search_api.search_with_pagination("å¤•é˜³", max_results=100)
    print(f"ğŸ“Š æ€»æœç´¢ç»“æœ: {len(all_results)} æ¡")
    
    # 3. é«˜çº§æœç´¢
    print(f"\n3ï¸âƒ£ é«˜çº§æœç´¢æ¼”ç¤º")
    from datetime import datetime, timedelta
    
    # æœç´¢æœ€è¿‘30å¤©åŒ…å«"å¤•é˜³"ä¸”æœ‰æ–‡ä»¶çš„å¤‡å¿˜å½•
    date_from = datetime.now() - timedelta(days=30)
    advanced_results = search_api.advanced_search(
        query="å¤•é˜³",
        has_files=True,
        date_from=date_from
    )
    
    print(f"ğŸ“¸ æœ€è¿‘30å¤©åŒ…å«'å¤•é˜³'ä¸”æœ‰å›¾ç‰‡çš„å¤‡å¿˜å½•: {len(advanced_results)} æ¡")
    
    # 4. è·å–æ–‡ä»¶ä¿¡æ¯
    if advanced_results:
        first_result = advanced_results[0]
        if first_result['files']:
            file_ids = [f['id'] for f in first_result['files']]
            file_details = search_api.get_file_details(file_ids)
            print(f"ğŸ“ æ–‡ä»¶è¯¦æƒ…: {len(file_details)} ä¸ªæ–‡ä»¶")
            
            for file_detail in file_details[:2]:  # æ˜¾ç¤ºå‰2ä¸ªæ–‡ä»¶
                print(f"   - {file_detail.get('name')} ({file_detail.get('size')} bytes)")
                print(f"     å›¾ç‰‡URL: {file_detail.get('url')}")
    
    print(f"\nğŸ‰ æœç´¢åŠŸèƒ½æ¼”ç¤ºå®Œæˆï¼")

if __name__ == "__main__":
    demo_search_functionality()